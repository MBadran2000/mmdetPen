{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycocotools import mask\n",
    "from skimage import measure\n",
    "import cv2\n",
    "\n",
    "CATEGORIES: dict[str, int] = {\n",
    "    \"SA\": 1,\n",
    "    \"LI\": 2,\n",
    "    \"RI\": 3,\n",
    "}\n",
    "\n",
    "def _shift(category_id: int, fragment_id: int) -> int:\n",
    "    return 10 * (category_id - 1) + fragment_id\n",
    "\n",
    "def load_masks(path) -> tuple[np.ndarray, list[int], list[int]]:\n",
    "    seg = np.array(Image.open(path))\n",
    "    return seg_to_masks(seg)\n",
    "\n",
    "def seg_to_masks(seg: np.ndarray) -> tuple[np.ndarray, list[int], list[int]]:\n",
    "    \"\"\"Convert a binary-encoded multi-label segmentation to masks.\"\"\"\n",
    "    category_ids = []\n",
    "    fragment_ids = []\n",
    "    masks = []\n",
    "    for category_id in CATEGORIES.values():\n",
    "        for fragment_id in range(1, 11):\n",
    "            mask = np.right_shift(seg, _shift(category_id, fragment_id)) & 1\n",
    "            if mask.sum() > 0:\n",
    "                masks.append(mask.astype('uint8'))\n",
    "                category_ids.append(category_id)\n",
    "                fragment_ids.append(fragment_id)\n",
    "\n",
    "    return np.array(masks), category_ids, fragment_ids\n",
    "\n",
    "\n",
    "def create_coco_annotation(img_id, annotation_id, category_id, binary_mask, image_size):\n",
    "    fortran_ground_truth_binary_mask = np.asfortranarray(binary_mask)\n",
    "    encoded_ground_truth = mask.encode(fortran_ground_truth_binary_mask)\n",
    "    ground_truth_area = mask.area(encoded_ground_truth)\n",
    "    ground_truth_bounding_box = mask.toBbox(encoded_ground_truth)\n",
    "    bool_mask = binary_mask > 0.5\n",
    "\n",
    "\n",
    "    contours, _ = cv2.findContours(\n",
    "            bool_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "    # contours = measure.find_contours(binary_mask, 0.5)\n",
    "\n",
    "    annotation = {\n",
    "            \"segmentation\": [],\n",
    "            \"area\": ground_truth_area.tolist(),\n",
    "            \"iscrowd\": 0,\n",
    "            \"image_id\": img_id,\n",
    "            \"bbox\": ground_truth_bounding_box.tolist(),\n",
    "            \"category_id\": category_id,\n",
    "            \"id\": annotation_id\n",
    "        }\n",
    "\n",
    "    for contour in contours:\n",
    "        contour = np.flip(contour, axis=1)\n",
    "        segmentation = contour.ravel().tolist()\n",
    "        annotation[\"segmentation\"].append(segmentation)\n",
    "\n",
    "def convert_to_coco_format(img_dir, ann_dir, output_file):\n",
    "    coco_dataset = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    # category_id = 1\n",
    "    categories = [{\"id\": 1, \"name\": \"SA\"} , {'id' : 2 , 'name': 'LI'} , {'id':3 , 'name': 'RI'}]\n",
    "    coco_dataset[\"categories\"] = categories\n",
    "\n",
    "    annotation_id = 1\n",
    "    img_id = 1\n",
    "    files = os.listdir(img_dir)\n",
    "    files.sort()\n",
    "    files = files[:50]\n",
    "    for img_filename in files:\n",
    "        img_path = os.path.join(img_dir, img_filename)\n",
    "        img = Image.open(img_path)\n",
    "        width, height = img.size\n",
    "        \n",
    "        image_info = {\n",
    "            \"file_name\": img_filename,\n",
    "            \"height\": height,\n",
    "            \"width\": width,\n",
    "            \"id\": img_id\n",
    "        }\n",
    "        coco_dataset[\"images\"].append(image_info)\n",
    "                \n",
    "        binary_masks , category_ids , fragment_ids = load_masks(os.path.join(ann_dir, img_filename) )\n",
    "\n",
    "        for binary_mask , category_id ,fragment_id in zip(binary_masks , category_ids , fragment_ids):\n",
    "            annotation = create_coco_annotation(img_id, annotation_id, category_id, binary_mask, (width, height))\n",
    "            # print(annotation)\n",
    "            coco_dataset[\"annotations\"].append(annotation)\n",
    "            annotation_id += 1\n",
    "        img_id += 1\n",
    "        print(img_id)\n",
    "\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(coco_dataset, f, indent=4)\n",
    "\n",
    "# Paths to your image and annotation directories\n",
    "img_dir = '/scratch/dr/y.nawar/pengwin/train/input/images/x-ray/'\n",
    "ann_dir = '/scratch/dr/y.nawar/pengwin/train/output/images/x-ray/'\n",
    "output_file = '/scratch/dr/y.nawar/pengwin/train/coco_annotations.json'\n",
    "\n",
    "convert_to_coco_format(img_dir, ann_dir, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pengwin_utils\n",
    "from PIL import Image\n",
    "\n",
    "image_path = \"/scratch/dr/y.nawar/pengwin/train/input/images/x-ray/001_0000.tif\"\n",
    "seg_path = \"/scratch/dr/y.nawar/pengwin/train/output/images/x-ray/001_0000.tif\"\n",
    "\n",
    "# load image and masks\n",
    "image = pengwin_utils.load_image(image_path) # raw intensity image\n",
    "masks, category_ids, fragment_ids = pengwin_utils.load_masks(seg_path)\n",
    "\n",
    "# save visualization of image and masks\n",
    "# applies CLAHE normalization to the raw intensity image before overlaying segmentations.\n",
    "vis_image = pengwin_utils.visualize_sample(image, masks, category_ids, fragment_ids)\n",
    "vis_path = \"vis_image.png\"\n",
    "Image.fromarray(vis_image).save(vis_path)\n",
    "print(f\"Wrote visualization to {vis_path}\")\n",
    "\n",
    "# Obtain predicted masks, category_ids, and fragment_ids\n",
    "# Category IDs are {\"SA\": 1, \"LI\": 2, \"RI\": 3}\n",
    "# Fragment IDs are the integer labels from label_{category}.nii.gz, with 1 corresponding to the main fragment.\n",
    "pred_masks, pred_category_ids, pred_fragment_ids = masks, category_ids, fragment_ids # replace with your model\n",
    "\n",
    "# save the predicted masks for upload to the challenge\n",
    "# Note: cv2 does not work with uint32 images. It is recommended to use PIL or imageio.v3\n",
    "pred_seg = pengwin_utils.masks_to_seg(pred_masks, pred_category_ids, pred_fragment_ids)\n",
    "pred_seg_path = \"pred/train/output/images/x-ray/001_0000.tif\" # ensure dir exists!\n",
    "Image.fromarray(pred_seg).save(pred_seg_path)\n",
    "print(f\"Wrote segmentation to {pred_seg_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import mmcv\n",
    "\n",
    "from mmengine.fileio import dump, load\n",
    "from mmengine.utils import track_iter_progress\n",
    "\n",
    "\n",
    "def convert_balloon_to_coco(ann_file, out_file, image_prefix):\n",
    "    data_infos = load(ann_file)\n",
    "\n",
    "    annotations = []\n",
    "    images = []\n",
    "    obj_count = 0\n",
    "    for idx, v in enumerate(track_iter_progress(data_infos.values())):\n",
    "        filename = v['filename']\n",
    "        img_path = osp.join(image_prefix, filename)\n",
    "        height, width = mmcv.imread(img_path).shape[:2]\n",
    "\n",
    "        images.append(\n",
    "            dict(id=idx, file_name=filename, height=height, width=width))\n",
    "\n",
    "        for _, obj in v['regions'].items():\n",
    "            assert not obj['region_attributes']\n",
    "            obj = obj['shape_attributes']\n",
    "            px = obj['all_points_x']\n",
    "            py = obj['all_points_y']\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "\n",
    "            x_min, y_min, x_max, y_max = (min(px), min(py), max(px), max(py))\n",
    "\n",
    "            data_anno = dict(\n",
    "                image_id=idx,\n",
    "                id=obj_count,\n",
    "                category_id=0,\n",
    "                bbox=[x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                area=(x_max - x_min) * (y_max - y_min),\n",
    "                segmentation=[poly],\n",
    "                iscrowd=0)\n",
    "            annotations.append(data_anno)\n",
    "            obj_count += 1\n",
    "\n",
    "    coco_format_json = dict(\n",
    "        images=images,\n",
    "        annotations=annotations,\n",
    "        categories=[{\n",
    "            'id': 0,\n",
    "            'name': 'balloon'\n",
    "        }])\n",
    "    dump(coco_format_json, out_file)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    convert_balloon_to_coco(ann_file='data/balloon/train/via_region_data.json',\n",
    "                            out_file='data/balloon/train/annotation_coco.json',\n",
    "                            image_prefix='data/balloon/train')\n",
    "    convert_balloon_to_coco(ann_file='data/balloon/val/via_region_data.json',\n",
    "                            out_file='data/balloon/val/annotation_coco.json',\n",
    "                            image_prefix='data/balloon/val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '001_002.tif'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pengwin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
